{
    "collab_server" : "",
    "contents" : "##########################\n# This master script performs Approximate Bayesian Analysis\n#     algorithms and goodness-of-fit testing for the Paleo simulations\n#         USES THE ABC PACKAGE (for post-hoc elimination-style ABC)\n#\n#  Authors: Kevin Shoemaker and Damien Fordham\n# \n#  22 May 2017 -- started scripting\n#\n##########################\n\nrm(list=ls())\n\n####################\n# LOAD PACKAGES\n###################\n\n##ABC code\nlibrary(abc)\nlibrary(raster)\nlibrary(ggmap)\nlibrary(mapproj)\nlibrary(rworldmap)\nlibrary(abctools)    # for fancy calibration of the posterior - for later? \n\n####################\n# LOAD SIMULATION RESULTS\n###################\n\n\nwd <- \"E:\\\\Dropbox\\\\Damien Fordham\\\\Mammoth Model\\\\Kevin\\\\MergedInputs\\\\\"\n\nwd_results <- \"E:\\\\MammothResults\\\\ABCAnalysisInputs\\\\\"\n\nsetwd(wd)\ndat1 <- read.csv(sprintf(\"%sNicheBreadth40_ABC_data_revised.csv\",wd), header = T,stringsAsFactors = FALSE)\ndat2 <- read.csv(sprintf(\"%sNicheBreadth50_ABC_data_revised.csv\",wd), header = T,stringsAsFactors = FALSE)\ndat3 <- read.csv(sprintf(\"%sNicheBreadth60_ABC_data_revised.csv\",wd), header = T,stringsAsFactors = FALSE)\ndat4 <- read.csv(sprintf(\"%sNicheBreadth70_ABC_data_revised.csv\",wd), header = T,stringsAsFactors = FALSE)\ndat5 <- read.csv(sprintf(\"%sNicheBreadth80_ABC_data_revised.csv\",wd), header = T,stringsAsFactors = FALSE)\ndat6 <- read.csv(sprintf(\"%sNicheBreadth90_ABC_data_revised.csv\",wd), header = T,stringsAsFactors = FALSE)\n\nall <- rbind(dat1,dat2,dat3,dat4,dat5,dat6)\nnrow(all)\n\nhead(all)\n\n\n### remove all sims that never went extinct or extinct in first time step\n\n#keep <- !is.na(all$extinction_yrs)\n\n#length(which(keep))\n\n#all <- all[keep,]     # remove the ca. 55k simulations that were not plausible. \n\n  # explore any remaining NAs in the data frame\n\n#remaining.nas <- all[which(is.na(all),arr.ind=TRUE),]\n\n#nrow(remaining.nas)     # 480 simulations with NAs for dist_centroid and dist_fossil\n\n####################\n# LOAD REAL WORLD DATA\n####################\n\n    # load data on effective population size from genetic data\ngendat <- read.csv(\"E:\\\\MammothResults\\\\ABCAnalysisTargets\\\\Genetic\\\\Mammoth_Ne.csv\", header = T)\n\n   # load data on extinction date from the fossil record, interpolated to entire range\n#extdat <- read.csv(\"E:\\\\MammothResults\\\\ABCAnalysisTargets\\\\Fossil\\\\interprolated_estimate_xyz.csv\", header = T)\n\n  # load data on extinction date from the fossil record, only fossil locations... \nextdat <- read.csv(\"E:\\\\MammothResults\\\\ABCAnalysisTargets\\\\Fossil\\\\Barnoski_matched_estimates_fossils.csv\", header = T)\nextdat_fossilsites <- extdat[extdat$Fossil.Data==1,]\n\nlast.locations <- extdat[which(extdat$Ext==min(extdat$Ext)),c(1,2)]\n\nnames(last.locations) <- c(\"X\",\"Y\")\n\n\n\n\n## plot out the real-world data\n\n\n\n####################\n# OBSERVED STATISTICS FOR MATCHING WITH SIMULATION RESULTS\n###################\n\ntest.statistics.obs <- c(64.0765, 11.4448, 0, 0, 0, 0)\n\nnames(test.statistics.obs) <- c(\"abundcoef1\",\"abundcoef2\",\"extinctpattern\",\"extinction_yrs\",\"dist_centroid\",\"dist_fossil\")\n\ntest.statistics.obs\n\n####################\n# SET UP VARIABLEs FOR ABC\n###################\n\n      #### What is the multivariate parameter space we are attempting to estimate?\n\nestimable.params <- c(\n  \"RMAX\",      \n  \"SD\",        # env. stochasticity\n  \"ALLEE\",     \n  \"DENSITY\",   # max density of mammoths\n  \"DISP1\",     # determines rate of staying/leaving a given cell\n  \"DISP2\",     # max dispersal distance\n  \"HARV\",      # maximal harvest rate\n  \"HARVZ\",     # regulates shape of functional response\n  \"HUMAN\",\n  \"summ_precip_median\",\n  \"summ_precip_range\",\n  \"jan_temp_median\",\n  \"jan_temp_range\",\n  \"jul_temp_median\",\n  \"jul_temp_range\"\n)\n\nestimable.params\n\n   #### Which test statistics should we use? \n\ntest.statistics <- c(\n  \"abundcoef1\",    # slope of abundance decline, most recent\n  \"abundcoef2\",     # slope of abuncance decline, older\n  \"extinctpattern\",\n  \"extinction_yrs\",\n  \"dist_centroid\",\n  \"dist_fossil\"\n)\n\ntest.statistics\n\n\n## use just coefficient 1 (abundance by itself) \n\n## timing of extinction is critical\n\n## play around with both distances but don't use both...\n\n## pattern by itself\n\n## pattern with extinction?   bring NAs in?\n\n\n\n\n\n#####################\n# VISUALIZE PRIORS (check for uniformity- don't need to run this every time)\n#####################\n\n## plot parameters \nvisualize.priors <- function(){\n  par(mfrow=c(2, 3),ask=TRUE)\n  \n  for(i in 1:length(estimable.params)){\n    hist(all[,estimable.params[i]], breaks = 50,main=estimable.params[i])\n  }\n}\n  \n# visualize.priors()\n\n\n#####################\n# PERFORM BASIC VISUALIZATIONS AND DATA CHECKS\n#####################\n \n\n\n   # prepare data for ABC\n\nprepareForABC <- function(data=all,subset=c(1,3)){\n  par.sim <<- data[,estimable.params]     # samples run from parameter space \n  stat.sim <<- scale(data[,test.statistics[subset],drop=FALSE])    # statistics to match with the real data\n  stat.obs <<- test.statistics.obs[test.statistics[subset]]\n}\n\nprepareForABC(all,subset=c(1:6))\n\n\nhead(stat.sim)\n\n\n####################\n# SELECT SUMMARY STATISTICS\n####################\n\n\n### remove all na observations\n\nall_nona <- na.omit(all)\n\nprepareForABC(all_nona,subset=c(1:6))\n\nselectstats <- abctools::selectsumm(test.statistics.obs, par.sim, \n                                     stat.sim, ssmethod =AS.select,\n                                     final.dens = FALSE)\n\nselectstats\n\n?selectsumm\n\n\n\n\nprepareForABC(all,subset=c(1,3))   # go back to using all observations.\n\n\n# best subset is variables 1 and 3...\n\n\n#####################\n# PERFORM PRELIMINARY ABC, VISUALIZATIONS AND DATA CHECKS\n#####################\n\n### Using the rejection Method to find the best fits\n\n\n#####\n# ABC analysis\n#####\nrej <- abc(target=stat.obs, param=par.sim, sumstat=stat.sim, tol=.01, method =\"neuralnet\")   # rejection  # loclinear\n\n\nhead(rej$adj.values)\nhead(rej$unadj.values)\nrej$weights\n\nrej$dist\n\n######     \n # summary and diagnostic plots\n######\n\nplot(rej,param=par.sim)\n\nrej$ss\n\n    ### credible intervals\nsummary(rej)\n\n\n\n    ### cross validation (can take a while with neural net)\n\ncv.res.reg <- cv4abc(data.frame(Density=par.sim$DENSITY,Allee=par.sim$ALLEE), stat.sim,\n                     nval=20, tols=c(0.005,0.01), method=\"rejection\")\nplot(cv.res.reg)\n\nsummary(cv.res.reg)   # good summary of model performance\n\n\n\n\n### find the best simulations to explore further\n\nif(length(test.statistics)>1){\n  ndx <- as.numeric(rownames(rej$ss))\n  mins <- apply(as.matrix(rej$ss,min),2,min)\n}else{\n  ndx <- as.numeric(names(rej$ss))\n  ndx_min <- as.numeric(names(which(rej$ss == min(rej$ss), arr.ind = TRUE)))[1]\n  mins <- apply(as.matrix(rej$ss,min),2,min)\n}\n\n\n\n\n#############################\n# VISUALIZE ABUNDANCE TRAJECTORIES\n#############################\n\nindex <- ndx[1]\nindex <- ndx_min\n\ntarget <- all[index,]$model\n#toPlot <- \"ABUNDANCE\"\ntoPlot <- \"EXTINCTION_DATE\"\n\nvisualize <- function(target=target,toPlot=toPlot){\n  \n  if(toPlot=\"EXTINCTION_DATE\"){\n    matches <- as.numeric(unlist(regmatches(target, gregexpr(\"[[:digit:]]+\", target))))\n    nichebreadth <- matches[1]\n    sample <- matches[2]\n    \n    \n    if(toPlot==\"ABUNDANCE\") filename <- sprintf(\"NicheBreadth%i_TotAbund_output_alldata.csv\",nichebreadth)\n    \n    setwd(wd_results)\n    getwd()\n    \n    list.files()\n    \n    \n    abund <- read.csv(filename, header = T)    # if(!\"abund\"%in%ls(name=.GlobalEnv))  \n    \n    head(abund[,2000:2010])\n    \n    time<- rev(seq(from =0, to =80000, by = 25))\n    \n    timeall <- time[2361:2928]\n    timebreak1 <- time[2708:2928]\n    timebreak2 <- time[2361:2707]\n    \n    ## Provide row id of simulation of interest\n    abundall <- as.numeric(abund[sample,2362:2929])     \n    abundbreak1 <- as.numeric(abund[sample,2709:2929])\n    abundbreak2 <- as.numeric(abund[sample,2362:2708])\n    \n    graphics.off()\n    plot(timeall, abundall, pch = 16, cex = 0.2, col = \"blue\", main = \"Change in Ne\", \n         ylim=c(0,min(1000000,max(abundall+10000))),xlab = \"Time (year)\", ylab = \"Abundance\")   #  ,\n    \n    break1coef <- round(lm(abundbreak1~timebreak1)$coefficients[2],2) \n    break2coef <- round(lm(abundbreak2~timebreak2)$coefficients[2],2)\n    \n    abline(lm(abundbreak1~timebreak1))\n    abline(lm(abundbreak2~timebreak2))\n  \n    \n    ## Extinction presumed to have occurred by 3000 years ago; and only interested in records after 21,000 years ago\n    time2 <- (gendat[61:420,1])\n    abund2 <-(gendat[61:420,2])\n    data2 <- cbind(time2, abund2)\n    \n    points(time2, abund2, cex = 0.1, col = \"red\",pch=20)\n  }\n  \n\n  if(toPlot=\"EXTINCTION_DATE\"){\n    matches <- as.numeric(unlist(regmatches(target, gregexpr(\"[[:digit:]]+\", target))))\n    nichebreadth <- matches[1]\n    sample <- matches[2]\n    \n    colname <- sprintf(\"NicheBreadth%i_LHS_Sample%i.mp\",nichebreadth,sample)\n    \n    filename <- sprintf(\"NicheBreadth%i_FinalYear_output_alldata_formatted.csv\",nichebreadth)\n    \n    setwd(wd_results)\n    \n    extinct <- read.csv(filename, header = T)    # if(!\"abund\"%in%ls(name=.GlobalEnv))  \n    \n    xcords <- extinct[,1]\n    ycords <- extinct[,2]\n    head(extinct[,1:10])\n    \n    thissample <- extinct[,colname]\n    \n    time<- rev(seq(from =0, to =80000, by = 25))\n    \n    ext.time <- time[thissample]\n    \n    exttime_scaled <- ext.time/80000\n    \n    cols <- colorRamp(c(\"blue\",\"red\"), bias = 1, space = c(\"rgb\"),\n                      interpolate = c(\"linear\"), alpha = FALSE)(exttime_scaled)\n    \n    \n    #map <- get_map(location = 'Asia', zoom = 3)\n    newmap <- getMap(resolution = \"low\")\n    #ggmap(map)\n    \n    \n    \n    par(mfrow=c(2,1))\n    plot(newmap,xlim = c(20, 180),\n         ylim = c(30, 71),\n         asp = 1,\n         main=\"simulated\"\n         )\n    points(xcords,ycords,pch=20,cex=0.01,col=cols)\n    \n    \n    plot(newmap,xlim = c(20, 180),\n         ylim = c(30, 71),\n         asp = 1,\n         main=\"real\"\n    )\n    cols <- colorRamp(c(\"blue\",\"red\"), bias = 1, space = c(\"rgb\"),\n                      interpolate = c(\"linear\"), alpha = FALSE)(extdat$Ext/80000)\n    \n    points(extdat$Mammoth_estimates.CI.Barnoski._Long,extdat$Mammoth_estimates.CI.Barnoski._Lat,pch=20,cex=0.01,col=cols)    \n    \n    \n    points(last.locations)\n    \n    \n     ### location of final extinction\n    ndx <- which(ext.time==min(ext.time,na.rm=T))\n    xcords_lastext <- extinct[ndx,1]\n    ycoord_lastext <- extinct[ndx,2]\n    \n    plot(newmap,xlim = c(50, 219),\n         ylim = c(30, 71),\n         asp = 1,\n         main=\"real\"\n    )\n    points(xcords_lastext,ycoord_lastext,pch=20,cex=3,col=\"black\")\n    points(last.locations)\n    \n  }  \n  \n}\n\n\n\n\nvisualize(target,toPlot)\n\n\n\n\n\n#####################\n# VISUALIZE POSTERIORS\n#####################\n\nvisualize.posteriors <- function(){\n  par(mfrow=c(2, 3),ask=TRUE)\n  \n  posterior_ndx <- as.numeric(rownames(as.matrix(rej$ss))) \n  all_post <- all[posterior_ndx,]\n  for(i in 1:length(estimable.params)){\n    hist(all_post[,estimable.params[i]], breaks = 50,main=estimable.params[i])\n  }\n}\n\nvisualize.posteriors()\n\n\n\n\n?abc\n\n\n\n\n\n\n\n\n\n\nall$\n\n\n\n\n\n## ABC with local linear regression correction without/with correction\n## for heteroscedasticity\n##\n\nlin <- abc(target=stat.obs, param=par.sim, sumstat=stat.sim, tol=.1, hcorr = FALSE, method = \"loclinear\", transf=c(\"none\",\"log\"))\n\n\n\nlinhc <- abc(target=stat.obs, param=par.sim, sumstat=stat.sim, tol=.1, method =\n               \"loclinear\", transf=c(\"none\",\"log\"))\n\n\n\n\n#####################\n# from ABC package\n\n## Note: cv4postpr is only for model selection...\n          # also \"postpr\" is only for model selection\n          # use \"cv4abc\" function for our purposes\n\n\n## Note: the neural network method seems to be the best- local linear does not work at all!\n\n\n\nlibrary(abc)\ndata(human)\ncv.modsel <- cv4postpr(models, stat.3pops.sim, nval=50, tol=.01, method=\"mnlogistic\")   # Not applicable\nplot(cv.modsel)    # not applicable\n\nstat.italy.sim <- subset(stat.3pops.sim, subset=models==\"bott\")    # \ncv.res.reg <- cv4abc(data.frame(Na=par.italy.sim[,\"Ne\"]), stat.italy.sim,\n                       nval=200, tols=c(.005,.001), method=\"loclinear\")\nplot(cv.res.reg, caption=\"Ne\")\n\nres <- abc(target=stat.voight[\"italian\",], param=data.frame(Na=par.italy.sim [, \"Ne\"]),\n             + sumstat=stat.italy.sim, tol=0.005, transf=c(\"log\"), method=\"neuralnet\")\nplot(res, param=par.italy.sim [, \"Ne\"])\n\n\n\n\n\n\n\n\n\n\n\n\n\n##### TESTS\n\n# does removing nas do anything to the results? it shouldn't!\n\n\n",
    "created" : 1495475778011.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2498711672",
    "id" : "9C6782AA",
    "lastKnownWriteTime" : 1495729968,
    "last_content_update" : 1495729968724,
    "path" : "E:/GIT/paleo-models-sandbox/ABC_Mammoth_Code.R",
    "project_path" : "ABC_Mammoth_Code.R",
    "properties" : {
    },
    "relative_order" : 7,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}